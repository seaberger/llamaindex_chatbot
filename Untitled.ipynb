{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d9b8919-9211-4269-9088-0c7a45e4f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# llama-parse is async-first, running the async code in a notebook requires the use of nest_asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb3cc93c-e487-430f-b300-f6aef6034924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the API through environment variable\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "llama_cloud_api_key = os.getenv('LLAMA_CLOUD_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fc80341-4be1-4f87-ac45-ab5ac60040a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model=OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo-0125\")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6498e5c-785a-40ce-9752-411d84a644dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started parsing the file under job_id da6a1c2b-8ced-4d0e-a6e5-bc29a653aa94\n"
     ]
    }
   ],
   "source": [
    "from llama_parse import LlamaParse\n",
    "from pathlib import Path\n",
    "\n",
    "# This constructs a Path object for the \"data\" directory.\n",
    "data_dir = Path('data')\n",
    "\n",
    "# This constructs the full path to \"attention.pdf\" within the \"data\" directory.\n",
    "file_path = data_dir / 'uber_10q_march_2022.pdf'\n",
    "\n",
    "# Use the constructed path in your method call\n",
    "documents = LlamaParse(result_type=\"text\").load_data(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20a956a2-8056-4e86-bed5-56397f300d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________\n",
      "                                                Delaware                                                                                                     45-2647441\n",
      "           (State or other jurisdiction of incorporation or organization)                                                                  (I.R.S. Employer Identification No.)\n",
      "                                                                                                   1515 3rd Street\n",
      "                                                                                       San Francisco, California 94158\n",
      "                                                                    (Address of principal executive offices, including zip code)\n",
      "                                                                                                   (415) 612-8582\n",
      "                                                                        (Registrantâ€™s telephone number, including area code)\n",
      "                           ...\n"
     ]
    }
   ],
   "source": [
    "print(documents[0].text[2000:3000] + '...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ead6af27-6dfc-4ecd-8018-ea136e7e2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import MarkdownElementNodeParser\n",
    "\n",
    "node_parser = MarkdownElementNodeParser(llm=OpenAI(model=\"gpt-3.5-turbo-0125\"), num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b4454b2-8a36-4de8-ad86-d9f7c1b7bf8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n",
      "0it [00:00, ?it/s]\n",
      "/home/seanb/miniforge3/lib/python3.10/site-packages/tiktoken/core.py:50: RuntimeWarning: coroutine 'LlamaParse.aload_data' was never awaited\n",
      "  self._core_bpe = _tiktoken.CoreBPE(mergeable_ranks, special_tokens, pat_str)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36450c38-e915-4278-9dd3-0debdfb6d49f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
